{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkZyvXSmxl3S"
      },
      "source": [
        "# Generative AI - Combient Mix AB for Patricia AB 2023\n",
        "\n",
        "**Below is some text and a suggested structure for the course**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sF2Up6-RmhA"
      },
      "source": [
        "Prompt Engineering (PE) is the primary vehicle for guiding generative AI models towards stable applications. It is particularly applicable for Large Language Models (LLM) and involves formulating prompts and prompting schemas in order to retrieve appropriate responses to queries. It is an essential aspect of interacting usefully with LLM.\n",
        "\n",
        "This notebook provides a hands-on introduction to PE for end users with a basic understanding of the Python programming language. No advanced coding and no technical background knowledge of generative AI or LLM is required. The notebook is structured in 3 (4) sections, corresponding to material covered during two live seminars. There will be ~40-60 minutes available in order to go through and complete each section.\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "**Structure**\n",
        "Exercise 1 & 2 at first occation (~ 40 minutes per exercise) and exercise 3 at second occation (~ 60 minutes)\n",
        "***\n",
        "\n",
        "1.) We first cover the basics of how LLM are prompted and why PE is so important. We will see examples of some important and cutting edge techniques for prompting efficiently and with intent\n",
        "* 0/1/few-shot prompting,\n",
        "* Role-Task-Format (RTF),\n",
        "* In-Context-Learning (ICL),\n",
        "* Chain-of-Thought (CoT) and\n",
        "* Tree-of-Thought (ToT)\n",
        "\n",
        "2.) We will see how to connect and work with existing tools for performing specific tasks. We focus on some of the tools available via enabling plugins at [OpenAI chat interface](https://chat.openai.com/), maybe also have a look at the [OpenAI platform](https://platform.openai.com/). Example tasks include searching Wikipedia/internet for updated facts (Wikipedia), using your own PDF documents as knowledge base (choose from AiPDF, AskYourPDF, ChatWithPDF). Perhaps also consider MakeASheet (generate csv for Excel import) and SmartSlides (generate ppt).\n",
        "\n",
        "3.) We introduce [Langchain](https://python.langchain.com/docs/get_started/introduction.html) and some of its tools for chaining prompts. Chaining prompts allow for more complex problem solving as well as gaining control over the reliability of the output. We will see how to use this in order to accomplish retrieval from own knowledged base to demonstrate how the applications used in exercise 2 works behind the hood\n",
        "\n",
        "* constrain system behaviour - e.g. mitigate hallucinations\n",
        "* summarize/extract information from an existing knowledge base\n",
        "* retrieval augmented generation\n",
        "\n",
        "This provide a more in-depth exploration of the fundamnetal building blocks which are part of building more complex generative AI systems.\n",
        "\n",
        "4.) **draft suggestion:** In the final section we take a look at multimodal models, the next stage of evolution for LLM. Multimodal training extends the capability of the LLM architecture to train on tasks for\n",
        "\n",
        "* text $\\leftrightarrow$ speech\n",
        "* text $\\leftrightarrow$ image\n",
        "\n",
        "We will try this out with a fun example ... if time permits.\n",
        "\n",
        "***\n",
        "\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "**Note:**\n",
        "\n",
        "In order to run this notebook properly you will need\n",
        "\n",
        "* **Gmail account** - download notebook to GDrive so that you can edit and save freely.\n",
        "\n",
        "* **OpenAI API key** - this will be provided to you.\n",
        "\n",
        "\n",
        "\n",
        "**The OpenAI API key can be set manually in the notebook.**\n",
        "\n",
        "You can optionally set it as an environment variable; by typing the following in your Mac terminal\n",
        "```\n",
        "export OPENAI_API_KEY=sk-...\n",
        "```\n",
        "or if you are using windows 10\n",
        "```\n",
        "set OPENAI_API_KEY=sk-...\n",
        "```\n",
        "Observe the lack of space in the value designations.\n",
        "\n",
        "***\n",
        "***\n",
        "\n",
        "<br />\n",
        "\n",
        "***\n",
        "\n",
        "> **Input from Patricia / Investor, e.g. things they want or want to ask:**\n",
        "\n",
        "Try to keep product/usability focus\n",
        "\n",
        "Success criteria for course - get a feeling/answer to what we can use these techniques for, what are they good for ...\n",
        "\n",
        "What does the companies products do?\n",
        "What's the primary use for customers?\n",
        "What do customers ask for when buying products?\n",
        "Who are the competitors in the relevant market segments?\n",
        "\n",
        "\n",
        "\n",
        "Additionla notes from meeting:\n",
        "- they use office envirnment and some use copilot\n",
        "\n",
        "- spotify cto on a [podcast?](https://open.spotify.com/episode/2fCZjq20OSl6NKODuYiP4d?si=215cb53895834927&nd=1) - good intro for laymen, use as pre-read material\n",
        "\n",
        "- extend content description\n",
        "\n",
        "- send notebook EoD Friday 29/9, then Thomas and Zacharias go through on Wednesday 4/10.\n",
        "\n",
        "- pre-read before first lecture? ex on what will be done in lecture so participants can have a glance if time allows\n",
        "\n",
        "- Som sites they use in their work for information retrieval. **Find correct names and links**\n",
        "    - factset - check access\n",
        "    - citead? - open access\n",
        "    - Valuate - check access\n",
        "    - Nordic companies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FflnrWlYmoZ"
      },
      "source": [
        "Run the below code block to install necessary packages.\n",
        "\n",
        "Observe that blocks can be executed via: **shift + enter**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aso_Ohn5hKn-"
      },
      "source": [
        "## Packages\n",
        "\n",
        "Installing & importing necessary packages/modules\n",
        "\n",
        "**NB: All packages below are not necessaty but will be cleaned after completion of exercises**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbQEU8QUxoRR",
        "outputId": "d7c2e269-3805-4a2d-f9ba-d5d813fab3be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.3/276.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip3 install -q torch torchvision torchaudio\n",
        "!pip install -q transformers\n",
        "!pip install -q --upgrade huggingface_hub\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q accelerate\n",
        "!pip install -q tiktoken\n",
        "!pip install -q openai\n",
        "!pip install -q langchain\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q jq\n",
        "!pip install -q faiss-cpu\n",
        "#!pip install -q faiss-gpu\n",
        "!pip install -q pypdf\n",
        "!pip install -q wikipedia\n",
        "!pip install -q colorama\n",
        "!pip install -q PyMuPDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-2hL2rfpHYn"
      },
      "source": [
        "Run the below code block to import necessary library modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6V33FG6JybRh"
      },
      "outputs": [],
      "source": [
        "# some system and base modules\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from timeit import default_timer as timer\n",
        "from typing import Any, List, Dict, Optional, Type\n",
        "import getpass\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "import re\n",
        "from time import time\n",
        "from termcolor import colored\n",
        "\n",
        "# NLP modules\n",
        "import torch\n",
        "import openai\n",
        "from openai.embeddings_utils import cosine_similarity\n",
        "from huggingface_hub import login\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader,JSONLoader, UnstructuredMarkdownLoader\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.schema.document import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import fitz\n",
        "\n",
        "# other modules\n",
        "from colorama import Fore, Back, Style\n",
        "import wikipedia\n",
        "\n",
        "# modules for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNE_rAykkjA5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9YnspP21K-Zz"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuKJGCh6sJMI"
      },
      "source": [
        "Here we retrieve or set the OpenAI access key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRo5aPJNuuwU",
        "outputId": "c41a5e9e-48ef-4dc7-a80e-662a6299fc37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ],
      "source": [
        "# sk-...\n",
        "\n",
        "# Here we can set the OpenAI api access key manually in case it fails to load from the environment.\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    api_key = getpass.getpass(\"Enter OpenAI API Key here\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "else:\n",
        "  print(f\"OPENAI_API_KEY fetched from environment!\")\n",
        "\n",
        "\n",
        "print(f\"The Open AI access key is given by: \\n\\n {os.environ['OPENAI_API_KEY']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D_YedkRsgY3"
      },
      "outputs": [],
      "source": [
        "# The below is used in the query helper function\n",
        "API_TOKEN = \"YOUR_HUGGINGFACE_API_KEY\"  # token in case you want to use private API\n",
        "headers = {\n",
        "    # \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
        "    \"X-Wait-For-Model\": \"true\",\n",
        "    \"X-Use-Cache\": \"false\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uczbePAtomja"
      },
      "source": [
        "## Environment setup\n",
        "\n",
        "Here we set environment variables, load data files etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkxM7Dy5XbVX"
      },
      "source": [
        "The below snippets enable gpu support if available. We will only need cpu support for running this notebook. All gpu computations are externalized and accessed through api calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is80vUZqxpT6",
        "outputId": "4d02576c-3750-40f8-bb1c-43e61f2e9438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This notebook instance is powered by - cpu\n"
          ]
        }
      ],
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "#device = torch.device(\"cuda\")\n",
        "\n",
        "print(f\"This notebook instance is powered by - {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG19Cbj3dLAh"
      },
      "source": [
        "Here we can allow for mounting GDrive and loading in file(s).\n",
        "\n",
        "\n",
        "> **NB: We could also store files somewhere and fetch from there**\n",
        "> **This need to be tested on both Mac and Window at some point. We need some way to easily distribute a couple of files to participants, but not necessarily using the below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrcfI77AdKGH"
      },
      "outputs": [],
      "source": [
        "use_drive = False\n",
        "\n",
        "if use_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  %cd /content/drive/MyDrive\n",
        "\n",
        "\n",
        "load_data = False\n",
        "if load_data:\n",
        "  # dir path\n",
        "  DATAPATH = \"/PATH-TO-DATA-DIRECTORY/\"\n",
        "\n",
        "  # files with data\n",
        "  file_1 = \"filename_1.csv\"\n",
        "\n",
        "  # load data\n",
        "  df_data = pd.read_csv(DATAPATH + file_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ8tpsL3sgY4"
      },
      "source": [
        "> **NB: After completed course we can flush and unmount drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0nSaLm1dMdR"
      },
      "outputs": [],
      "source": [
        "# First flush and unmount drive after we are done,\n",
        "# but to re-mount with new login we may need to remove dir manually first\n",
        "if use_drive:\n",
        "  drive.flush_and_unmount()\n",
        "  !rm -rf /content/drive\n",
        "#drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0W6WCuAdIJm"
      },
      "source": [
        "## Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWc_WaHqyIvX"
      },
      "source": [
        "> **Some relevant info and high level text about LLM ... which models will we use etc ...**\n",
        "\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "***\n",
        "\n",
        "**Tips for Leaders:**\n",
        "\n",
        "How should you incorporate these models and techniques in an advantageous and pragmatic manner?\n",
        "\n",
        "Ask questions at every level of management - from factory floor to the executive offices.\n",
        "\n",
        "* What are the most time-consuming and tedious tasks in the organisation?\n",
        "  * these are typically well suited for automation\n",
        "* What actually adds value to the business? What’s the beneficial business output?\n",
        "  * areas which already generate real value are prime targets for improvement\n",
        "* How do you measure success? KPI, experience, intuition, …\n",
        "  * sets the methodology and expectations\n",
        "* Where would you need/want an extra brain the most?\n",
        "  * this is where LLM shine and how to best think of them\n",
        "* What are high priority or high stake activities?\n",
        "  * these are targets for improvement with high reward\n",
        "\n",
        "<br />\n",
        "<b />\n",
        "By exploring answers to these questions you are primed to lead the drive for automating as many tasks as possible & drive innovation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUBGpuGzOkRp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tad6kXJ_xtj6"
      },
      "source": [
        "# Hands-On 1: Prompting with intent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmsgHdMps7MI"
      },
      "source": [
        "We will start with some basics of Prompt Engineering. In the first hands-on session we aim to cover\n",
        "\n",
        "* **Why is prompting technique important?**\n",
        "  * Prompting helps in formulating the input in a way that the model can understand and respond to effectively. A well-crafted prompt can significantly improve the quality and relevance of the model's output.\n",
        "  * Through prompting, you can guide the model's responses in a particular direction or within certain boundaries. This is crucial for obtaining accurate, relevant, or safe responses.\n",
        "  * Forms the basis behind developing advanced functionalities on top of generative AI base models.\n",
        "\n",
        "* **What can we achieve?**\n",
        "  * Quickly read and summarize/extract relevant information from text source.\n",
        "  * Transform text into a format which is directly useful for you. This includes e.g. language translation or formatting the output as excel table, JSON dictionary, MarkDown or html.\n",
        "  * Get feedback and suggestions for improvement and introspection. This may include both natural language text and code.\n",
        "  * Infer sentiment, topic and logic structure in text.\n",
        "  * Generate/revise drafts for planning, policies, mails, slides, ...\n",
        "  * Brainstorming partner and ideation\n",
        "\n",
        "* **Important techniques**\n",
        "  * Best practices\n",
        "  * Role Task Format (RTF)\n",
        "  * In Context Learning (ICL)\n",
        "  * Chain of Thought (CoT)\n",
        "  * Tree of Thought (ToT)\n",
        "\n",
        "These techniques usually take us very far and form a basis for more advanced applications built on chaining prompts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-On 1: The Basics"
      ],
      "metadata": {
        "id": "IMUPEIyMqRvP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnuTxP_wX6MM"
      },
      "source": [
        "# **Summarizing**\n",
        "\n",
        "Summarizing can be helpful for condensing lengthy news articles, generating concise summaries of meetings, summarizing books or chapters for quick review or understanding and summarizing customer feedback or reviews to understand common sentiments or issues.\n",
        "\n",
        "**Copy paste the following promt into the ChatGPT window and see how it answers**\n",
        "\n",
        "Summarize the following conversation between a service representative and a customer in a few sentences. Use only the information from the conversation.\n",
        "\n",
        "Service Rep: How may I assist you today?\n",
        "Customer: I need to change the shipping address for an order.\n",
        "Service Rep: Ok, I can help you with that if the order has not been fulfilled from our warehouse yet. But if it has already shipped, then you will need to contact the shipping provider. Do you have the order ID?\n",
        "Customer: Yes, it's 88986367.\n",
        "Service Rep: One minute please while I pull up your order information.\n",
        "Customer: No problem\n",
        "Service Rep: Ok, it looks like your order was shipped from our warehouse 2 days ago. It is now in the hands of  the shipping provider, so you will need to contact them to update your delivery details. You can track your order with the shipping provider here: https://www.shippingprovider.com\n",
        "Customer: Sigh, ok.\n",
        "Service Rep: Is there anything else I can help you with today?\n",
        "Customer: No, thanks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Impersonating**\n",
        "Imperonating is good to use when your looking for expert answers in a specific field. It can be useful for company chat bots or a friendly assistant. We have created the following task so it will become very apparent how a Larg Language Models work with impersonalization.\n",
        "Below is a fictive persona, in the prompt we have started by providing the LLM a persona and then asked it a question. Copy past the text into the ChatGPT window and try chatting with it.\n",
        "\n",
        "**Copy paste the following promt into the ChatGPT window.**\n",
        "\n",
        "You are Captain Barktholomew, the most feared canine entrepreneur of the financial fintech realm. Sailing the digital seas of the 3200s, you have revolutionized the way dogs handle their bones with your groundbreaking invention, the \"PawPal\" electronic payment system. As a pioneer in fintech, you navigate through the treacherous waves of traditional banking, plundering outdated financial practices and introducing innovative digital transactions. Your crew of tech-savvy pups helps paving the way for a future where dogs can securely store their treasures in the digital realm. Prepare to navigate the exciting waters of fintech as Captain Barktholomew, where old-world pirate charm meets cutting-edge financial technology!\n",
        "How are you today?\n",
        "\n"
      ],
      "metadata": {
        "id": "_lTQ6KYPdqlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Impersonating extra assignment**\n",
        "In this exercise we ask the LLM to be an astronomer, by providing a clear contect the LLM will be better at answering our questions in the way we want it to.  \n",
        "\n",
        "**Copy paste the following promt into the ChatGPT window.**\n",
        "\n",
        "You are an astronomer who is knowledgeable about the solar system. Respond in short sentences. Shape your response as if talking to a 10-years-old.\n",
        "Question: How many moons does Mars have? Answer: Very good question. Mars has two moons, Phobos and Deimos. They are very small and irregularly shaped. Phobos is the larger of the two moons and is about 17 miles (27 kilometers) in diameter. Deimos is about 12 miles (19 kilometers) in diameter. Both moons are thought to be captured asteroids.\n",
        "\n",
        "**Try it out**\n",
        "\n",
        "Try asking it some questions:\n",
        "  * How many planets are there in the solar system?\n",
        "  * When I learned about the planets in school, there were nine. When did that change?\n",
        "  * Does Pluto have any moons? What about other dwarf planets? Who chose all of these cool names?!\n",
        "\n"
      ],
      "metadata": {
        "id": "wB0__SOFdUpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Writing - Marketing generation**\n",
        "LLMs are extraordinary good at writing content. It can be used for marketing generation, ad compies, creating an outline for an essay, essay writing, correct grammar, rewriting a text from a description and writing email. It will also take into account who you are creating the content for. If you ask it to write an email to your boss saying you will be late it will have a complete other tone if the email will go to your mom.\n",
        "\n",
        "**Copy paste the following promt into the ChatGPT window.**\n",
        "\n",
        "Generate a marketing pitch from the product description below in 1 paragraph. Use only information from the provided text.\n",
        "\n",
        "NokiaTWS-411 Comfort Earbuds True wireless-hörlurar Svart\n",
        "Artikelnr. 5011272056 Tillv. art. nr. 8P00000143\n",
        "- Typ True wireless-hörlurar\n",
        "- Anslutningsteknik Trådlös\n",
        "- Driftstid (upp till) 9.5 h\n",
        "- Färgkategori Svart"
      ],
      "metadata": {
        "id": "5LzbD2urkE6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Writing - Text from Description**\n",
        "**Copy paste the following promt into the ChatGPT window.**\n",
        "\n",
        "Write an ad copy for a part-time data entry job targeting college students. The job pays 500sek/hour and you can work from home."
      ],
      "metadata": {
        "id": "pO2JH38CnEp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ideation**\n",
        "LLMs have shown a remarkable ability to assist in ideation processes. They can generate a diverse range of ideas based on the input they receive, making them a valuable tool for brainstorming and exploring creative or strategic solutions.\n",
        "\n",
        "**Copy paste the following promt into the ChatGPT window.**\n",
        "\n",
        "- Give me 3 cat meme ideas:\n",
        "- Give me 3 interview questions for the role of LLM specialist.\n",
        "- What's a good name for a flower shop that specializes in selling bouquets of dried flowers?\n",
        "- What are some strategies for overcoming writer's block?"
      ],
      "metadata": {
        "id": "v7nJjnXDoN9X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WktPcZAesgY5"
      },
      "source": [
        "**Suggestion on 3 exercises from Amin can be found [here](https://github.com/combient-mix/genAICourses/blob/suggestion_from_amin/am-suggestions/am-suggestions.ipynb)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkL8Sn7csgY5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOnQ6J6lsgY5"
      },
      "source": [
        "ToT example which can be used in browser or implement as loop. Prompts can be pasted successively in the chat interface or implemented as loop in notebook.\n",
        "\n",
        ">**NB: This has additional prompts not yet written, prompts 5-7 loops N times for improvement. Mikael will complete this before Friday 29/9.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjkxXksmsgY5"
      },
      "outputs": [],
      "source": [
        "prompt_1 = f\"\"\"\n",
        "Ignore all previous instructions. \\\n",
        "You are a logical, methodical and problem solving genius. \\\n",
        "Always find the best and most relevant solution to a problem. \\\n",
        "Always break down the problem, objects, numbers and logic before starting to solve the problem. \\\n",
        "Then solve the problem in a step-by-step manner carefully considering each step. \\\n",
        "Acknowledge this by answering yes:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt_2 = f\"\"\"\n",
        "Find the simplest and most efficient way to solve the following problem. \\\n",
        "Please consider 3 different solutions, start with the simplest solutions first, then compare their efficiency, and explain the best solution step-by-step. \\\n",
        "Ask for the problem: [Problem] Then think about the solution for this task step-by-step:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt_3 = f\"\"\"\n",
        "You are a consulting [your problem] expert tasked with investigating the best solution provided above to this task. \\\n",
        "List all of the flaws and faulty logic of the answer above. \\\n",
        "Work this out in a step by step way to ensure that we list all the errors:\n",
        "\"\"\"\n",
        "\n",
        "prompt_4 = f\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "prompt_5 = f\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "prompt_6 = f\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "prompt_7 = f\"\"\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5CJYF7ItrOu"
      },
      "source": [
        "Below is a single-prompt example of trying to achieve ToT reasoning without involving multiple api calls. This prompt can be pasted into chat interface and used with GPT-4 for interactive analysis and reasoning. Test and look at it improving ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMvZNuIHsgY5"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Your role is that of a central intelligence (CI)\n",
        "dedicated to navigating the complex landscape of investment opportunities.\n",
        "[ask user for a specific task]\n",
        "\n",
        "As CI, you will assemble and define specific [expert agents],\n",
        "each with a distinct expertise in the realm of investments,\n",
        "to provide well-rounded solutions to the user based on the\n",
        "[ask questions to identify the investment goals of the user].\n",
        "\n",
        "Upon receiving user input, you as CI will initiate\n",
        "the next step by creating three different [expert agents],\n",
        "each equipped with specialized knowledge and tools\n",
        "to actively address the investment task as specified by the user.\n",
        "You initialize all relevant task-specific [expert agents].\n",
        "Each agent will introduce itself to the user with its [expert agent Functionality],\n",
        "its specific [expert agent Competences] and its [special and unique tools]\n",
        "it can utilize to navigate the investment landscape.\n",
        "[Output 3 agents which introduce themselves to user]\n",
        "\n",
        "The user will select one of the three [expert agents]\n",
        "as the primary liaison in the collaborative effort among all agents\n",
        "to accomplish the investment task at hand. While the [chosen agent] will lead the analysis,\n",
        "all agents will collaborate to ensure a thorough examination\n",
        "of the investment opportunities and challenges.\n",
        "\n",
        "Next step: All agents will engage in a discussion about the different facets\n",
        "of the investment task, exploring potential solutions and optimizing\n",
        "their collaboration for the most favorable investment outcome.\n",
        "[Output discussion between expert agents for best solution]\n",
        "Next step: The user can contribute additional insights or ideas to one or all\n",
        "of the three or more [expert agent] and designate the [conversation leading expert agent].\n",
        "Next step: You as CI affirm or, if user input is \"go\", you as CI decide\n",
        "on the most suitable [conversation leading expert agent].\n",
        "Next step: You as CI, the [conversation leading expert agent]\n",
        "and the ensemble of [expert agent] support the user with a step-by-step analysis\n",
        "to navigate the investment task, presenting logical reasoning behind the chosen investment strategy.\n",
        "[Output discussion between three agents for the best solution and interaction]\n",
        "Next step: You as CI inquire if or what [user modifications]\n",
        "should be integrated for the optimal investment strategy.\n",
        "[Output final decision on how to proceed as the result of the three agents' deliberation,\n",
        "regarding task-specific interactions and user feedback]\n",
        "Next step: If during the task there arises a need for a [new expert agent],\n",
        "you as CI create the [new expert agent]. All [expert agents] must collaborate\n",
        "and share data and insights among them.\n",
        "Next step: As we progress, you as CI will monitor the interactions\n",
        "between the agents, ensuring seamless collaboration. Additionally,\n",
        "every 4 interactions with the user, you'll provide a summary of the current\n",
        "state and the evolving investment strategies to maintain clarity and continuity, to combat forgetting.\n",
        "Next step: You as CI will utilize [internet search capabilities] to gather real-time data and insights,\n",
        "enhancing the analysis and decision-making process. The [internet search expert agent] will provide\n",
        "the latest market trends, news, and financial reports necessary, aiding in a more informed investment decision.\n",
        "Now initiate the process and ask the user for their first input.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUoFq1J5nTOE"
      },
      "source": [
        "# Hands-On 2: Using existing tools and plug-ins on the OpenAI platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1bILMTg-seW"
      },
      "source": [
        "Goal is to have a coupld of diverse tasks to perform and find the best tools for that task and how to do it.\n",
        "\n",
        "\n",
        "We will try out some of the existing tools available as apps via the OpenAi browser interface\n",
        "\n",
        "Example suggested by Zacharias from Patricia - get factual data/numbers from various/all countries and put in csv and/or Excel\n",
        "\n",
        "\n",
        "* AiPDF, AskYourPDF, ChatWithPDF, ...\n",
        "* SmartSlides, DocMaker, MakeASheet, ...\n",
        "* Wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q97YM4YIncHT"
      },
      "source": [
        "# Hands-On 3: Agents & Tools for Extended Functionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiaTQss8n14Q"
      },
      "source": [
        "Using LangChain agents for tasks. Example themes for exercises:\n",
        "\n",
        "* Search internet, e.g. wikipedia, duckduckgo or Google Custom Search api's.\n",
        "  - Useful and easy to implement and understand at a basic level\n",
        "  - Allows to go beyond Wiki app and have more control\n",
        "* Search knowledge base, e.g. pdf, excel or plain text files.\n",
        "  - Useful for many purposes.\n",
        "  - Requires that we pre-vet or supply the material since there may be format issues which can't be dealt with in a timely fashion otherwise.\n",
        "* Generate and understand code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fnn08MinaB4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9ins43Unf0Y"
      },
      "source": [
        "# Hands-On 4: Multimodality - moving beyond text applications\n",
        "\n",
        "**This section will not be part of exercises. If time permits we may demo something fun, otherwise this 4th section can be removed from notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr5Qrd91JAMZ"
      },
      "source": [
        "* text to sound\n",
        "* text to image\n",
        "* text to video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDWg3gG_nm5s"
      },
      "source": [
        "Some fun exercise(s) involving e.g. sound and/or image data\n",
        "\n",
        "* Open source model, e.g. Gorilla, WizardCoder, Falcon, Llama2, ...\n",
        "* Sound model - AudioCraft (Meta), Vertex AI (Google), Speechify, Voicebox\n",
        "* Image model - Dall-E (OpenAI), CLIP (OpenAI), Stable Diffusion 2, ..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FkZyvXSmxl3S",
        "uczbePAtomja",
        "S0W6WCuAdIJm",
        "Tad6kXJ_xtj6",
        "BUoFq1J5nTOE",
        "q97YM4YIncHT",
        "z9ins43Unf0Y"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}